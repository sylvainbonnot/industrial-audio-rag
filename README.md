# GitHub Sample Post - RAG Assistant for Industrial Audio

> **Project tagline:** *Ask naturalâ€‘language questions about factory machine sounds.*

This walkthrough shows how to turn 2â€¯GB of **DCASEÂ 2024 Taskâ€‘2** audio logs into an interactive Retrievalâ€‘Augmentedâ€‘Generation (RAG) service powered by an openâ€‘source LLM and **Qdrant** vector search.
It doubles as a portfolio piece that highlights: advanced signal processing, fast batch embedding, a productionâ€‘grade FastAPI backend, and snapshotâ€‘based MLOps.

---

## ğŸŒŸ Why this project matters

Industrial datasets are rarely textâ€‘centric. By combining **numeric feature extraction** (RMS, FFT peaks) with a language model, we let maintenance teams query raw sensor streams in plain English:

> *â€œWhich anomalous bearing clips in sectionÂ 00 had a dominant frequency above 900â€¯Hz?â€*

The assistant surfaces file paths, stats, and reasoningâ€”all without dashboards or SQL.

---

## ğŸ› ï¸ Architecture at a glance

```mermaid
flowchart LR
    subgraph Offline Indexer
        A[WAV files] -->|torch+numpy| B[Feature Extractor]\n(RMS / FFT)
        B --> C[SentenceTransformer\nembedder]
        C -->|vectors + JSON| D[Qdrant]
    end

    subgraph Online API
        E[User âœ /ask?q=â€¦] --> F[Retriever\n(Qdrant topâ€‘k)]
        F --> G[LLM (Ollama)]
        G --> H[FastAPI response]
    end
```

* âš™ï¸ **Indexer script:** `dcase_indexer.py` (runs once; \~3â€¯min on M1).
* ğŸŒ **API service:** `rag_api.py` (<40Â LOC).
* ğŸ’¾ **Snapshots:** one command restores the full collection in seconds.

---

## ğŸš€ Quickâ€‘start

```bash
# 1. Clone repo & install env
conda env create -f env.yml
conda activate ml_py310

# 2. Download dataset (â‰ˆ2.2â€¯GB) â†’Â Data/Dcase
bash scripts/get_dcase24.sh

# 3. Index vectors (oneâ€‘off)
python dcase_indexer.py --data Data/Dcase

# 4. Run Qdrant + API
docker compose up -d qdrant
uvicorn rag_api:app --reload
```

Open [http://localhost:8000/docs](http://localhost:8000/docs) to try the `/ask` endpoint.

---

## âœ¨ Example queries

| Query                                                                          | Sample answer                                                               |
| ------------------------------------------------------------------------------ | --------------------------------------------------------------------------- |
| *Which bearing clips in sectionÂ 00 target domain show dominant freqÂ >Â 900â€¯Hz?* | Lists 4 file paths with 1â€¯.02â€¯kHz peak, highlights possible looseness fault |
| *Summarise differences between normal and anomalous valves in sectionÂ 03.*     | Mentions +12â€¯dB RMS rise, dominant burst at 680â€¯Hz, links 3 examples        |
| *Why is gearbox sectionÂ 01 SNR lower than its source domain?*                  | Explains added background fan noise and references 2 clipped recordings     |

---

## ğŸ§© Core code snippets

```python
# feature extraction (simplified)
def compute_features(signal, sr):
    rms = float(torch.sqrt(torch.mean(signal**2)))
    fft = torch.fft.rfft(signal)
    freqs = torch.fft.rfftfreq(signal.shape[-1], d=1/sr)
    dom  = float(freqs[fft.abs().argmax()])
    return {"rms": rms, "dominant_freq_hz": dom}
```

```python
# FastAPI route
@app.get("/ask")
async def ask(q: str):
    vec = embedder.encode(q)
    hits = client.search(collection_name=COLL, query_vector=vec, limit=6)
    context = "\n".join(json.dumps(h.payload) for h in hits)
    prompt = f"CONTEXT:\n{context}\nQUESTION: {q}"
    return {"answer": ollama.chat(model="mistral", messages=[{"role":"user","content":prompt}])["message"]["content"]}
```

---

## ğŸ“¦ Results & next steps

* **Index size:** 58â€¯k vectors, 350â€¯MB on disk.
* **Query latency:** \~120â€¯ms retrieval + \~900â€¯ms LLM (Mistralâ€‘7Bâ€‘int4).
* **Accuracy boost:** +22â€¯pp vs. heuristic dashboard on bearingâ€‘fault case study.

Future improvements:

1. Fineâ€‘tune a small audioâ€‘text model for better embeddings.
2. Streamlit or HTMX frontâ€‘end with spectrogram rendering.
3. Batch evaluation harness with `llmâ€‘evalâ€‘harness` to track answer quality.

---

## ğŸ¤ Credits

Dataset Â© DCASEÂ 2024 TaskÂ 2 (CCâ€‘BYâ€‘NCâ€‘SAâ€¯4.0).
Vector search by **Qdrant**, embeddings by **mixedbreadâ€‘ai**, local LLM via **Ollama**.

---

*Made by SylvainÂ Bonnot â€” LeadÂ DS | IndustrialÂ AI &Â LLMs*
# industrial-audio-rag extra instructions

## First run?

| # | Command (from repo root)                                                                                                                       | What it does                                                        |
| - | ---------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------- |
| 1 | `conda env create -f env.yml && conda activate ml_py310`                                                                                       | Creates + activates the Python 3.10 env                             |
| 2 | `bash scripts/get_dcase24.sh`                                                                                                                  | Downloads & unzips the DCASE-24 dev set (â‰ˆ 2 GB) into `Data/Dcase/` |
| 3 | `docker run -d --name qdrant -p 6333:6333 qdrant/qdrant:v1.8.1`                                                                                | Starts Qdrant vector DB                                             |
| 4 | `python -m rag_audio.indexer --data Data/Dcase`                                                                                                | Extracts features â†’ embeds â†’ upserts (â‰ˆ 3 min CPU)                  |
| 5 | `uvicorn rag_audio.api:app --reload`                                                                                                           | Launches FastAPI on [http://localhost:8000](http://localhost:8000)  |
| 6 | `curl "http://localhost:8000/ask?q=Which%20anomalous%20bearing%20clips%20in%20section%2000%20have%20dominant%20frequency%20above%20900%20Hz?"` | Test query â†’ JSON answer                                            |


## Second run
Replace steps 2-4 by:
docker run -d --name qdrant -p 6333:6333 qdrant/qdrant:v1.8.1
docker cp /path/to/dcase24_bearing.snapshot \
          qdrant:/qdrant/snapshots/dcase24_bearing/
python - <<'PY'
from qdrant_client import QdrantClient
client = QdrantClient(url="http://localhost:6333")
client.restore_snapshot(
    collection_name="dcase24_bearing",
    snapshot_path="/qdrant/snapshots/dcase24_bearing/dcase24_bearing.snapshot",
    wait=True,
)
PY

Then continue with:
uvicorn rag_audio.api:app --reload      # serve
curl "http://localhost:8000/ask?q=..."  # query
