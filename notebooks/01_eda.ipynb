{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Dataset exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "**Prereqs:** `conda activate ml_py310` then `pip install seaborn librosa ipywidgets`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# auto-load variables from .env in repo root, if present\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except ImportError:\n",
    "    pass   # falls back to bare os.environ\n",
    "\n",
    "DATA_DIR = Path(os.getenv(\"DCASE_DATA\", \"Data/Dcase\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(os.getenv(\"DCASE_DATA\", \"Data/Dcase\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def print_directory_tree(start_path, show_files=True):\n",
    "    \"\"\"\n",
    "    Prints the directory tree structure starting from `start_path`, similar to the `tree` command.\n",
    "    \n",
    "    Args:\n",
    "        start_path (str or Path): The root directory path to visualize.\n",
    "        show_files (bool): Whether to list files in directories.\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def _walk(path, prefix=\"\"):\n",
    "        nonlocal file_count, dir_count\n",
    "        contents = list(path.iterdir())\n",
    "        \n",
    "        if not show_files:\n",
    "            contents = [p for p in contents if p.is_dir()]\n",
    "\n",
    "        # Sort: directories first, then files\n",
    "        contents.sort(key=lambda p: (not p.is_dir(), p.name))\n",
    "\n",
    "        for i, path_entry in enumerate(contents):\n",
    "            is_last = i == len(contents) - 1\n",
    "            new_prefix = \"└── \" if is_last else \"├── \"\n",
    "            print(f\"{prefix}{new_prefix}{path_entry.name}\")\n",
    "\n",
    "            if path_entry.is_dir():\n",
    "                dir_count += 1\n",
    "                next_prefix = \"    \" if is_last else \"│   \"\n",
    "                _walk(path_entry, prefix + next_prefix)\n",
    "            elif show_files:\n",
    "                file_count += 1\n",
    "\n",
    "    # Initialize counters\n",
    "    file_count = 0\n",
    "    dir_count = 0\n",
    "\n",
    "    start_path = Path(start_path)\n",
    "\n",
    "    print(start_path)\n",
    "    if not start_path.exists():\n",
    "        print(f\"  [Error: Path does not exist]\")\n",
    "        return\n",
    "\n",
    "    _walk(start_path)\n",
    "\n",
    "    # Print summary\n",
    "    if show_files:\n",
    "        print(f\"\\n{dir_count} directories, {file_count} files\")\n",
    "    else:\n",
    "        print(f\"\\n{dir_count} directories\")\n",
    "\n",
    "print_directory_tree(DATA_DIR, show_files=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Count number of files per class\n",
    "class_counts = Counter()\n",
    "for root, dirs, files in os.walk(DATA_DIR):\n",
    "    #if 'fold' in root:  # Only count train folds\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                class_name = os.path.basename(root)\n",
    "                class_counts[class_name] += 1\n",
    "\n",
    "print(class_counts.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.barplot(x=list(class_counts.values()), y=list(class_counts.keys()))\n",
    "plt.title('Number of Audio Files Per Class')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Listen to one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import random\n",
    "\n",
    "\n",
    "machine = \"ToyCar\"\n",
    "split    = \"train\"\n",
    "wav_list = list(Path(DATA_DIR, machine, split).glob(\"*.wav\"))\n",
    "sample_path = random.choice(wav_list)\n",
    "class_name  = machine\n",
    "\n",
    "print(f\"Class: {class_name}\")\n",
    "display(Audio(sample_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_waveform(file_path):\n",
    "    signal, sr = librosa.load(file_path, sr=None)\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.title(os.path.basename(file_path))\n",
    "    plt.plot(signal)\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Amplitude\")\n",
    "    plt.show()\n",
    "\n",
    "plot_waveform(sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mfcc(file_path):\n",
    "    signal, sr = librosa.load(file_path, sr=None)\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfccs, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title('MFCC')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_mfcc(sample_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Stats on files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import soundfile as sf\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "durations = []\n",
    "\n",
    "# Walk through each class folder\n",
    "for class_folder in sorted(os.listdir(DATA_DIR)):\n",
    "    class_path = os.path.join(DATA_DIR, class_folder)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    for split in ['train', 'test']:\n",
    "        split_path = os.path.join(class_path, split)\n",
    "        if not os.path.exists(split_path):\n",
    "            continue\n",
    "\n",
    "        for file in os.listdir(split_path):\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(split_path, file)\n",
    "                try:\n",
    "                    signal, sr = sf.read(file_path)\n",
    "                    duration = len(signal) / sr\n",
    "                    durations.append({\n",
    "                        'class': class_folder,\n",
    "                        'split': split,\n",
    "                        'duration': duration\n",
    "                    })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error reading {file_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_durations = pd.DataFrame(durations)\n",
    "print(df_durations.groupby(['class', 'split'])['duration'].agg(['mean', 'std', 'count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df_durations, x='class', y='duration', hue='split')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Audio File Duration Distribution per Class and Split')\n",
    "plt.ylabel('Duration (seconds)')\n",
    "plt.xlabel('Class')\n",
    "plt.legend(title='Split')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df_durations.groupby(['class', 'split'])['duration'].agg(['mean', 'std', 'count'])\n",
    "summary = summary.reset_index()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check variation within each class/split\n",
    "print(\"\\nUnique durations per class and split:\")\n",
    "for (cls, split), group in df_durations.groupby(['class', 'split']):\n",
    "    unique_lengths = group['duration'].round(2).nunique()\n",
    "    total_files = len(group)\n",
    "    print(f\"{cls} - {split}: {unique_lengths} unique durations out of {total_files} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mfcc_features(dataset_path, n_mfcc=13, sr_target=None, verbose=True):\n",
    "    \"\"\"\n",
    "    Traverse DCASE-style dataset structure and extract MFCC features.\n",
    "\n",
    "    Folder structure expected:\n",
    "        dataset_path/\n",
    "            class1/\n",
    "                train/\n",
    "                    *.wav\n",
    "                test/\n",
    "                    *.wav\n",
    "            class2/\n",
    "                train/\n",
    "                    *.wav\n",
    "                test/\n",
    "                    *.wav\n",
    "            ...\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str or Path): Path to root of dataset\n",
    "        n_mfcc (int): Number of MFCC coefficients to extract\n",
    "        sr_target (int or None): Target sample rate. If None, uses native rate.\n",
    "        verbose (bool): Whether to print progress\n",
    "\n",
    "    Returns:\n",
    "        features (np.ndarray): Array of shape (n_samples, n_mfcc) containing MFCC features\n",
    "        labels (list): List of corresponding class names\n",
    "        splits (list): List indicating 'train' or 'test' for each file\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    splits = []\n",
    "\n",
    "    # Get list of class folders\n",
    "    class_names = [d for d in os.listdir(dataset_path)\n",
    "                   if os.path.isdir(os.path.join(dataset_path, d))]\n",
    "\n",
    "    for class_name in sorted(class_names):\n",
    "        class_dir = os.path.join(dataset_path, class_name)\n",
    "\n",
    "        for split in ['train', 'test']:\n",
    "            split_dir = os.path.join(class_dir, split)\n",
    "\n",
    "            if not os.path.exists(split_dir):\n",
    "                if verbose:\n",
    "                    print(f\"Missing {split} folder in {class_name}\")\n",
    "                continue\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Processing {class_name}/{split}...\")\n",
    "\n",
    "            for file_name in os.listdir(split_dir):\n",
    "                if file_name.endswith('.wav'):\n",
    "                    file_path = os.path.join(split_dir, file_name)\n",
    "\n",
    "                    try:\n",
    "                        signal, sr = librosa.load(file_path, sr=sr_target)\n",
    "                        mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=n_mfcc)\n",
    "\n",
    "                        # Take mean over time to get single feature vector per file\n",
    "                        features.append(np.mean(mfccs, axis=1))\n",
    "                        labels.append(class_name)\n",
    "                        splits.append(split)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        if verbose:\n",
    "                            print(f\"❌ Error processing {file_path}: {e}\")\n",
    "\n",
    "    return np.array(features), labels, splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract features\n",
    "features, labels, splits = extract_mfcc_features(DATA_DIR, n_mfcc=13, sr_target=None)\n",
    "\n",
    "print(\"Features shape:\", features.shape)\n",
    "print(\"Labels count:\", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Reduce to 2D using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "features_2d = tsne.fit_transform(features)\n",
    "\n",
    "# Visualize\n",
    "sns.scatterplot(x=features_2d[:, 0], y=features_2d[:, 1], hue=labels, style=splits, palette='Set1')\n",
    "plt.title('t-SNE of MFCCs by Class and Split')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
